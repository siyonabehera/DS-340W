{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siyonabehera/DS-340W/blob/main/Data_Generation_340w.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Generation\n",
        "##Details:\n",
        "One row ~ one project\n",
        "\n",
        "Features:\n",
        "\n",
        "- `n_tasks` -> number of activities (project size)\n",
        "- `n_edges` -> number of precedence links\n",
        "- `network_density` -> how interconnected the tasks are {`n_edges`/ `n_tasks`^2}\n",
        "- `T_baseline` -> total duration from CPM using most-likely (m)\n",
        "- `cp_len` -> number of tasks on the critical path\n",
        "- `pct_critical_tasks` -> proportion of critical tasks {`cp_len`/`n_tasks`}\n",
        "- `avg_task_duration` -> mean(m) across all tasks\n",
        "- `variability` -> average uncertainty width {mean(p-o)}\n",
        "- `spi_early` -> {EV/PV} at 20% progress\n",
        "- `cpi_early` -> {EV/AC} at 20% progress\n",
        "- `instability` -> {std(T)} or variance of project durations across MC runs\n",
        "- `risk_exposure` -> fraction of MC runs exceeding {baseline*1.025}\n",
        "- `buffer_factor` -> buffer applied to baseline duration for 'on-time' threshold\n",
        "- `p_late_diag` -> sanity check\n",
        "\n",
        "Label:\n",
        "`label_delay` = 1 if p_late > 1.025, 0 otherwise\n",
        "\n",
        "##Steps:\n",
        "1. Generate DAGs randomly (at least for now, later can use)\n",
        "2. Generate PERT triplets\n",
        "3. Run CPM logic (forward/backward passes)\n",
        "4. Baseline definition\n",
        "5. EVM snapshot\n",
        "6. MC labels\n",
        "7. Feature engineering\n",
        "8. Write the csv\n"
      ],
      "metadata": {
        "id": "kE-fd0qBLSoq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20EX4YPzJYAv"
      },
      "outputs": [],
      "source": [
        "# front matter\n",
        "import math, random, statistics\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict\n",
        "import csv\n",
        "\n",
        "RNG = random.Random(42)          # answer to ultimate question of life, the universe, and everything :)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1: generate the DAGs-> no need for it to be connected (having dependencies per task is not necessary)\n",
        "@dataclass\n",
        "class ProjectSpec:\n",
        "    n_tasks: int\n",
        "    p_edge: float                # edge probability-> how likely is it that an edge exists from i to j\n",
        "    buffer_factor: float = 1.025  # can vary as needed -- why 1.15 tho-- explicitly mention in report/writeup\n",
        "\n",
        "def generate_dag(n: int, p_edge: float):\n",
        "  preds = [[] for i in range(n)]        # empty list for storing predecessors for each n\n",
        "  edges = []                            # stores (i,j) pairs\n",
        "\n",
        "  # build edges with p_edge from i to j (ensure acyclic nature)\n",
        "  for i in range(n):\n",
        "    for j in range(i+1, n):\n",
        "      if RNG.random() < p_edge:\n",
        "        edges.append((i, j))\n",
        "        preds[j].append(i)\n",
        "  return preds, edges\n",
        "\n",
        "# sanity check\n",
        "def is_acyclic(edges):\n",
        "    return all(i < j for i, j in edges)\n",
        "\n",
        "# topological sort\n",
        "def topo_sort(n: int, preds: List[List[int]]):\n",
        "    # by construction, 0,...,n-1 is already topologically sorted\n",
        "    return list(range(n))"
      ],
      "metadata": {
        "id": "pAi1MvlMbnGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mini test for checking DAG generation\n",
        "preds, edges = generate_dag(8, 0.2)\n",
        "print(len(edges), \"edges; acyclic:\", is_acyclic(edges))\n",
        "print(\"example\", preds[:])"
      ],
      "metadata": {
        "id": "Z6aukcX9jDiK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8c6e53-710a-46ba-8384-8798dd55073b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 edges; acyclic: True\n",
            "example [[], [], [0, 1], [2], [1], [3], [4], [1, 5, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 2: assign pert triplets with rules: m ~ Uniform(3,10); w ~ Uniform(1,5); o = max(0.5, m - 0.6*w); p = m + 0.4*w; o < m < p\n",
        "@dataclass\n",
        "class Pert:\n",
        "  o: float\n",
        "  m: float\n",
        "  p: float\n",
        "def assign_triplets(n_tasks: int):\n",
        "  triplet = []\n",
        "  for i in range(n_tasks):\n",
        "    w = RNG.uniform(3,9)                    # uncertainty width for a task\n",
        "    m = RNG.uniform(3,10)                   # most like duration: 3-10 is plausible range for moderate tasks\n",
        "    o = max(0.5, m - 0.4*w)\n",
        "    p = m + 0.6*w                           # pessimistic-leaning\n",
        "    assert o <= m <= p and (p - o) > 1e-9   # sanity check\n",
        "    triplet.append(Pert(o,m,p))\n",
        "  return triplet"
      ],
      "metadata": {
        "id": "Vt6muwx95XWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mini test for checking triplets\n",
        "pert = assign_triplets(8)\n",
        "print(pert[:3])\n",
        "# spread should roughly scale with w → (p - o) ≈ (0.4+0.6)*w = 1.0*w (except clamped at 0.5)\n",
        "avg_range = sum(t.p - t.o for t in pert) / len(pert)\n",
        "print(\"avg (p-o):\", round(avg_range, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jmpB3gYAJ7L",
        "outputId": "5b287234-bebe-4081-9365-8a122ccaddd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pert(o=3.9920957403343333, m=7.226082219568237, p=12.077061938419092), Pert(o=4.971014650998212, m=8.108122506856725, p=12.813784290644495), Pert(o=7.324862928364313, m=9.811810347855594, p=13.542231477092518)]\n",
            "avg (p-o): 6.886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cpm: forward pass + backtrack; (ES, EF, T, cp) -> (earliest start, earliest finish, total duration, critical path)\n",
        "def cpm_early(preds: List[List[int]], durations: List[float], eps = 1e-9):\n",
        "  n = len(durations)\n",
        "  es = [0.0]*n\n",
        "  ef = [0.0]*n\n",
        "  order = topo_sort(n, preds)\n",
        "  for i in order:\n",
        "    if preds[i]:\n",
        "      es[i] =  max(ef[j] for j in preds[i]) if preds else 0.0\n",
        "    ef[i] = es[i] + durations[i]\n",
        "  T = max(ef)\n",
        "  # backtrack to get critical path\n",
        "  cp = []\n",
        "  i = ef.index(max(ef))                                      # position of largest EF (sink)\n",
        "  while True:\n",
        "    cp.append(i)                                             # since it is the last task, it definitely on the critical path\n",
        "    if not preds[i]:\n",
        "      break\n",
        "    options = [j for j in preds[i] if abs(ef[i]-ef[j]) < eps]\n",
        "    if options:\n",
        "      best_j = max(options, key= lambda j: ef[j])            # for multiple options, pick the one with the longest ef\n",
        "    else:\n",
        "      best_j = max(preds[i], key=lambda j: ef[j])            # fallback: pick pred with latest EF\n",
        "    i = best_j\n",
        "  cp.reverse()\n",
        "  return es, ef, T, cp"
      ],
      "metadata": {
        "id": "CjU_IrwDCBvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mini test for checking cp\n",
        "# A simple linear chain: 0 → 1 → 2\n",
        "preds = [[], [0], [1]]\n",
        "durations = [3, 5, 2]\n",
        "es, ef, T, cp = cpm_early(preds, durations)\n",
        "print(\"ES:\", es, \"\\nEF:\", ef, \"\\nT:\", T, \"\\nCP:\", cp)  # expect [0,3,8], [3,8,10], 10, [0,1,2]\n",
        "\n",
        "# diamond 0→1→3 and 0→2→3 (1-branch longer)\n",
        "preds = [[], [0], [0], [1,2]]\n",
        "d = [2,5,4,3]\n",
        "es, ef, T, cp = cpm_early(preds, d)\n",
        "print(\"\\nES:\", es, \"\\nEF:\", ef, \"\\nT:\", T, \"\\nCP:\", cp)  # expect ~[0,2,2,7], [2,7,6,10], 10, [0,1,3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfu-7-dEol1C",
        "outputId": "0d2ecdeb-e698-4423-a453-fb38ee8ebdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ES: [0.0, 3.0, 8.0] \n",
            "EF: [3.0, 8.0, 10.0] \n",
            "T: 10.0 \n",
            "CP: [0, 1, 2]\n",
            "\n",
            "ES: [0.0, 2.0, 2.0, 7.0] \n",
            "EF: [2.0, 7.0, 6.0, 10.0] \n",
            "T: 10.0 \n",
            "CP: [0, 1, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting baseline ES, EF, T, and CP by running CPM on the most likely values (from the triplets)\n",
        "def baseline_schedule(preds: List[List[int]], pert_triplets: List[Pert], buffer_factor= 1.03, eps = 1e-9):       # buffer factor of 2.5%-> strict, gives more variations in data\n",
        "  # extract most likely durations from Pert objects\n",
        "  m = [t.m for t in pert_triplets]\n",
        "  # run CPM on m_i\n",
        "  es_b, ef_b, T_b, cp = cpm_early(preds, m, eps)\n",
        "  # get deadline = buffer * baseline total duration\n",
        "  deadline = buffer_factor*T_b\n",
        "  # building output dictionary\n",
        "  out ={\n",
        "      \"baseline_T\": T_b,\n",
        "      \"baseline_es\": es_b,\n",
        "      \"baseline_ef\": ef_b,\n",
        "      \"baseline_cp\": cp,\n",
        "      \"deadline\": deadline,\n",
        "      \"buffer_factor\": buffer_factor\n",
        "  }\n",
        "  return out\n"
      ],
      "metadata": {
        "id": "YiHgRY-Drh7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mini test for generating baseline schedule\n",
        "preds, edges = generate_dag(8, 0.2)\n",
        "triplets = assign_triplets(8)\n",
        "base = baseline_schedule(preds, triplets, 1.025)\n",
        "base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RtCLAiMw69E",
        "outputId": "b397f68e-9ae0-4327-fac3-4988edcbffb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline_T': 19.45421456846099,\n",
              " 'baseline_es': [0.0,\n",
              "  7.472646464062036,\n",
              "  7.472646464062036,\n",
              "  7.472646464062036,\n",
              "  14.18512216942828,\n",
              "  0.0,\n",
              "  9.50369031385232,\n",
              "  11.54252134390948],\n",
              " 'baseline_ef': [7.472646464062036,\n",
              "  11.54252134390948,\n",
              "  14.248299674899416,\n",
              "  14.18512216942828,\n",
              "  19.45421456846099,\n",
              "  9.50369031385232,\n",
              "  18.325349019380575,\n",
              "  14.947997509368793],\n",
              " 'baseline_cp': [0, 3, 4],\n",
              " 'deadline': 19.940569932672513,\n",
              " 'buffer_factor': 1.025}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper-> sample duration d ~ Triangular(o,m,p)\n",
        "def sample_triangular(pert):\n",
        "  return [RNG.triangular(x.o, x.m, x.p) for x in pert]"
      ],
      "metadata": {
        "id": "UJpY1fjA9hTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early EVM snapshot: getting performance indices CPI, SPI\n",
        "def evm_snapshot(preds: List[List[int]], pert_triplets: List[Pert], ef_baseline: List[float], T_baseline: float, frac= 0.20, eps=1e-9):\n",
        "  # early snapshot time\n",
        "  t_early = T_baseline * frac\n",
        "  t_early = max(t_early, min(ef_baseline) + 1e-6)  # ensure ≥ first planned finish\n",
        "  # sample duration (single draw)\n",
        "  d = sample_triangular(pert_triplets)\n",
        "  # running cpm to get ef_real\n",
        "  es_real, ef_real, T_real, cp_real = cpm_early(preds, d, eps)\n",
        "  # defining aggregates pv, ev, ac-> planned value, earned value, actual cost\n",
        "  pv = sum(t.m  for i, t in enumerate(pert_triplets) if ef_baseline[i] <= t_early)\n",
        "  ev = sum(t.m  for i, t in enumerate(pert_triplets) if ef_real[i]     <= t_early)\n",
        "  ac = sum(d[i] for i, _ in enumerate(pert_triplets) if ef_real[i]     <= t_early)\n",
        "  # calculating performance indices spi, cpi-> schedule performance index, cost performance index\n",
        "  spi = ev/max(pv, eps)\n",
        "  cpi= ev/max(ac, eps)\n",
        "  # building output dictionary\n",
        "  out = {\n",
        "        \"t_early\": t_early,\n",
        "        \"PV\": pv, \"EV\": ev, \"AC\": ac,\n",
        "        \"SPI_early\": spi, \"CPI_early\": cpi\n",
        "        }\n",
        "  return out\n"
      ],
      "metadata": {
        "id": "-ESmr1iw7bT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds, edges = generate_dag(10, 0.18)\n",
        "trip = assign_triplets(10)\n",
        "base = baseline_schedule(preds, trip, 1.15)\n",
        "snap = evm_snapshot(preds, trip, base[\"baseline_ef\"], base[\"baseline_T\"])\n",
        "print(\"SPI: \", round(snap[\"SPI_early\"],3), \"\\nCPI: \", round(snap[\"CPI_early\"],3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzC423c0IX5C",
        "outputId": "bc5aedf0-efee-4839-9f70-d446baabdb76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPI:  1.391 \n",
            "CPI:  1.305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# monte carlo sims\n",
        "def monte_carlo_label(preds: List[List[int]], pert_triplets: List[Pert], deadline: float, K, eps=1e-9):\n",
        "  # init counter\n",
        "  count = 0\n",
        "  # run simulation K times-> sample duration, run cpm to get total duration for each run\n",
        "  for k in range(K):\n",
        "    d = sample_triangular(pert_triplets)\n",
        "    es_k, ef_k, T_k, cp_k = cpm_early(preds, d, eps)\n",
        "    # if total time is greater than the deadline, increment counter\n",
        "    if T_k > deadline:\n",
        "      count += 1\n",
        "  # p_late-> fraction of runs that finish late (empirical probability)\n",
        "  p_late = count/K\n",
        "  label = 1 if p_late >= 0.5 else 0      # label as delayed if p_late is greater than 0.5\n",
        "\n",
        "  return p_late, label"
      ],
      "metadata": {
        "id": "ls4ec1y9nIkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds, edges = generate_dag(10, 0.26)\n",
        "trip = assign_triplets(10)\n",
        "base = baseline_schedule(preds, trip, buffer_factor=1.03)\n",
        "\n",
        "\n",
        "p_late, label = monte_carlo_label(preds, trip, base[\"deadline\"], K=200)\n",
        "print(\"p_late:\", round(p_late,3), \"label:\", label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kEhzggbsivq",
        "outputId": "b4fbc68c-2fa9-45cc-d5d6-f59b1a8a6f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_late: 0.67 label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# putting it all together-> features for one row of the file\n",
        "def project_features(preds, edges, pert_triplets, base, snap, p_late, label):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    preds, edges            # structure\n",
        "    pert_triplets           # PERT triplets\n",
        "    base                    # dict from baseline_schedule\n",
        "    snap                    # dict from evm_snapshot\n",
        "    p_late, label           # from monte_carlo_label\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # structure:\n",
        "  n_tasks = len(preds)\n",
        "  n_edges = len(edges)\n",
        "  max_edges = n_tasks * (n_tasks - 1) / 2\n",
        "  density   = n_edges / max(max_edges, 1)\n",
        "  cp = base[\"baseline_cp\"]\n",
        "  cp_len = len(cp)\n",
        "  pct_critical_tasks = cp_len/max(n_tasks, 1)\n",
        "  T_baseline = base[\"baseline_T\"]\n",
        "\n",
        "  # uncertainty:\n",
        "  m_list = [t.m for t in pert_triplets]\n",
        "  ranges = [t.p - t.o for t in pert_triplets]\n",
        "  avg_task_duration = statistics.fmean(m_list)\n",
        "  variability = statistics.fmean(ranges)\n",
        "  instability = statistics.stdev(m_list)\n",
        "\n",
        "  # performance/early health:\n",
        "  spi_early = snap[\"SPI_early\"]\n",
        "  cpi_early = snap[\"CPI_early\"]\n",
        "\n",
        "  risk_exposure = p_late\n",
        "\n",
        "  # policy knobs:\n",
        "  buffer_factor = base[\"buffer_factor\"]\n",
        "  p_late_diag = p_late\n",
        "\n",
        "  # building dict:\n",
        "  row = {\n",
        "        # structure\n",
        "        \"n_tasks\": n_tasks,\n",
        "        \"n_edges\": n_edges,\n",
        "        \"density\": density,\n",
        "        \"critical_path_len\": cp_len,\n",
        "        \"pct_critical_tasks\": pct_critical_tasks,\n",
        "        \"T_baseline\": T_baseline,\n",
        "\n",
        "        # uncertainty\n",
        "        \"mean_m\": avg_task_duration,\n",
        "        \"mean_range_po\": variability,\n",
        "        \"instability_m\": instability,   # optional\n",
        "\n",
        "        # early health\n",
        "        \"spi_early\": spi_early,\n",
        "        \"cpi_early\": cpi_early,\n",
        "\n",
        "        # policy\n",
        "        \"buffer_factor\": buffer_factor,\n",
        "\n",
        "        # labels/diagnostics\n",
        "        \"label_delay\": label,\n",
        "        \"p_late_diag\": p_late,\n",
        "    }\n",
        "  return row"
      ],
      "metadata": {
        "id": "dFbX8ogtNiq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building full dataset\n",
        "DEFAULT_P_EDGE_RANGE = (0.24, 0.26)\n",
        "DEFAULT_BUFFER = 1.025\n",
        "DEFAULT_K = 200\n",
        "def synth_data(N: int,\n",
        "    p_edge_range: tuple[float, float] = DEFAULT_P_EDGE_RANGE,\n",
        "    buffer_factor: float = DEFAULT_BUFFER,\n",
        "    K: int = DEFAULT_K,\n",
        "    seed: int | None = None):\n",
        "\n",
        "  rows=[]\n",
        "\n",
        "  for proj_id in range(N):\n",
        "    n = RNG.randint(12, 35)\n",
        "\n",
        "    # --- structure ---\n",
        "    # choose p_edge\n",
        "\n",
        "    lo, hi = p_edge_range\n",
        "    p_edge = RNG.uniform(lo, hi)\n",
        "\n",
        "    preds, edges = generate_dag(n, p_edge)\n",
        "    # --- durations / uncertainty ---\n",
        "    # use your asymmetry/w ranges (already in assign_triplets)\n",
        "    trip = assign_triplets(n)\n",
        "\n",
        "    # --- baseline & early snapshot ---\n",
        "    base = baseline_schedule(preds, trip, buffer_factor=buffer_factor)\n",
        "    snap = evm_snapshot(preds, trip, base[\"baseline_ef\"], base[\"baseline_T\"])\n",
        "\n",
        "    # --- label via Monte Carlo ---\n",
        "    p_late, label = monte_carlo_label(preds, trip, base[\"deadline\"], K=K)\n",
        "\n",
        "    # --- assemble one row ---\n",
        "    row = project_features(preds, edges, trip, base, snap, p_late, label)\n",
        "\n",
        "    # optional metadata (can help debugging/splits)\n",
        "    row[\"proj_id\"]  = proj_id\n",
        "    row[\"p_edge\"]   = p_edge\n",
        "    row[\"n_tasks\"]  = len(preds)                  # ensure present even if project_features already sets it\n",
        "    row[\"buffer_factor\"] = base[\"buffer_factor\"]\n",
        "\n",
        "    rows.append(row)\n",
        "  return rows\n"
      ],
      "metadata": {
        "id": "WkeyYJLAHKVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write to csv:\n",
        "def write_csv(rows: List[Dict], path: str, round_cols: List[str] | None = None, ndigits: int = 3):\n",
        "    \"\"\"\n",
        "    Write rows to CSV, round selected float columns for readability.\n",
        "    \"\"\"\n",
        "    if not rows:\n",
        "        return\n",
        "    fields = list(rows[0].keys())\n",
        "\n",
        "    # rounding pass\n",
        "    if round_cols:\n",
        "        for r in rows:\n",
        "            for c in round_cols:\n",
        "                if c in r and isinstance(r[c], float):\n",
        "                    r[c] = round(r[c], ndigits)\n",
        "\n",
        "    with open(path, \"w\", newline=\"\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=fields)\n",
        "        w.writeheader()\n",
        "        w.writerows(rows)"
      ],
      "metadata": {
        "id": "4rimGC51fFQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaJPCjU2lYuT",
        "outputId": "89eca641-804b-4586-dee8-131d4f5b2a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "bWoNQlWYlfxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # TODO: set seed for reproducible dataset build (optional)\n",
        "    # RNG.seed(340)\n",
        "\n",
        "    rows = synth_data(\n",
        "        N=1500,\n",
        "        p_edge_range=(0.24, 0.26),\n",
        "        buffer_factor=1.025,\n",
        "        K=200,\n",
        "        seed=None\n",
        "    )\n",
        "\n",
        "    # choose which cols to round for pretty CSV\n",
        "    pretty_cols = [\n",
        "        \"T_baseline\", \"mean_m\", \"mean_range_po\",\n",
        "        \"spi_early\", \"cpi_early\", \"instability_m\", \"p_edge\", \"pct_critical_tasks\"\n",
        "        \"p_late_diag\", \"density\", \"avg_in_degree\"\n",
        "    ]\n",
        "    write_csv(rows, \"projects_sample_1500.csv\", round_cols=pretty_cols, ndigits=3)\n",
        "\n",
        "    print(f\"Wrote {len(rows)} rows → projects_sample.csv\")\n",
        "    # optional: quick label balance check\n",
        "    pos = sum(r[\"label_delay\"] for r in rows)\n",
        "    print(f\"label 1s: {pos}/{len(rows)} = {pos/len(rows):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHSFSnMZj0mP",
        "outputId": "0d9a553d-644c-498a-8467-a5b673213def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 1500 rows → projects_sample.csv\n",
            "label 1s: 814/1500 = 0.54\n"
          ]
        }
      ]
    }
  ]
}